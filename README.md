# ğŸš€ Vambe Analytics Dashboard

> **Panel de AnÃ¡lisis de Ventas** powered by Google Gemini AI

Dashboard que transforma transcripciones de reuniones con clientes en insights accionables usando Inteligencia Artificial.

---

## ğŸ¯ Â¿QuÃ© hace?

Usa **Google Gemini AI** para:
1. Categorizar automÃ¡ticamente cada transcripciÃ³n en 10 dimensiones
2. Calcular un Ãndice de Potencial (0-100) por lead
3. Identificar patrones y visualizar insights

### Resultado
**Decisiones basadas en datos**, no en intuiciÃ³n.

---

## ğŸ“Š MÃ©tricas Principales

### 1. Ãndice de Potencial de Lead (0-100) â­
Score automÃ¡tico basado en volumen, urgencia y escalabilidad.
- **80-100**: ğŸ”¥ Prioridad ALTA
- **60-79**: âš¡ Prioridad MEDIA  
- **40-59**: ğŸ“ Prioridad BAJA
- **<40**: â„ï¸ Descalificar

### 2. Tasa de Cierre
- Global + PronÃ³stico 6 meses
- Por vendedor (con benchmarking)
- DistribuciÃ³n de volumen numÃ©rico

### 3. Heatmap Sector Ã— Volumen
Identifica "sweet spots" de conversiÃ³n (ej: TecnologÃ­a + Alto volumen = 90%+ cierre)

### 4. ROI de Fuentes
Compara % leads vs % conversiÃ³n por canal de descubrimiento

### 5. Top Preocupaciones
Las 5 objeciones mÃ¡s comunes que bloquean cierres

### 6. Upsell Opportunities
Radar de 6 add-ons potenciales segÃºn demanda detectada

---

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos
- Python 3.9+
- Cuenta de Google (para API key gratuita)

### Pasos

1. **Crear entorno virtual**
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
```

2. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

3. **Configurar API Key**
```bash
cp .env.example .env
nano .env  # Pega GEMINI_API_KEY
```

4. **Ejecutar**
```bash
streamlit run app.py
# O simplemente: ./run.sh
```

---

## ğŸ’¾ CÃ³mo Funciona

### Primera Vez
1. Es necesario subir un archivo CSV/Excel con las columnas requeridas
2. El sistema valida el formato automÃ¡ticamente
3. Gemini categoriza cada transcripciÃ³n
4. Resultados se guardan en SQLite local

### Siguientes Veces
- Carga instantÃ¡nea desde la base de datos (< 1 seg)
- Se pueden subir mÃ¡s datos desde la barra lateral
- Los nuevos datos se agregan y categorizan automÃ¡ticamente

### Columnas Requeridas en CSV
- `Nombre` - Nombre del cliente/empresa
- `Correo Electronico` - Email de contacto
- `Numero de Telefono` - TelÃ©fono
- `Fecha de la Reunion` - Fecha (formato: DD/MM/YYYY)
- `Vendedor asignado` - Nombre del vendedor
- `closed` - Estado (0 = abierto, 1 = cerrado)
- `Transcripcion` - Texto completo de la reuniÃ³n

---

## ğŸ—ï¸ Arquitectura

### Estructura del Proyecto
```
vambe-analytics/
â”œâ”€â”€ app.py                      # AplicaciÃ³n principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ ai/                 # IntegraciÃ³n Gemini AI
â”‚   â”‚   â”œâ”€â”€ config/             # ConfiguraciÃ³n (API, schemas, colores)
â”‚   â”‚   â”œâ”€â”€ database/           # SQLite (modularizado: crud, duplicates, serialization)
â”‚   â”‚   â””â”€â”€ utils/              # Helpers (scoring, formatting, filters)
â”‚   â”œâ”€â”€ analytics/              # 8 mÃ©tricas (close_rate, roi, leads, etc)
â”‚   â”œâ”€â”€ data/                   # ValidaciÃ³n, carga, API de datos
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ components/         # Modularizado: file_reader, ai_processor, etc
â”‚       â”œâ”€â”€ tabs/               # 4 tabs principales
â”‚       â””â”€â”€ sidebar.py          # Barra lateral con filtros
â”œâ”€â”€ data_files/
â”‚   â””â”€â”€ vambe_processed.db      # SQLite database (auto-generada)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### Flujo de Datos
```
CSV/Excel Upload
    â†“
ValidaciÃ³n de schema
    â†“
Gemini AI (batch de 5)
    â†“
10 dimensiones extraÃ­das
    â†“
SQLite persistence
    â†“
Filtros + MÃ©tricas
    â†“
Visualizaciones Plotly
```

### Dimensiones ExtraÃ­das (10)
1. **sector_principal** - Industria principal
2. **sector_secundario** - Sub-categorÃ­a
3. **volumen_numerico** - NÃºmero exacto mencionado
4. **volumen_nivel** - Bajo/Medio/Alto/Muy Alto
5. **es_pico_estacional** - Boolean (picos o estable)
6. **fuente_primaria** - Canal de descubrimiento
7. **fuente_detalle** - Contexto especÃ­fico
8. **preocupaciones** - Array de objeciones (max 3)
9. **urgencia_nivel** - Baja/Media/Alta
10. **potencial_upsell** - Array de add-ons potenciales

---

## ğŸ§  Decisiones Clave de DiseÃ±o

### 1. Arquitectura Modular
**DecisiÃ³n:** Separar el cÃ³digo en mÃ³dulos independientes (`core`, `analytics`, `data`, `ui`)

**JustificaciÃ³n:**
- âœ… **Mantenibilidad:** Cada mÃ³dulo tiene una responsabilidad Ãºnica
- âœ… **Escalabilidad:** FÃ¡cil agregar nuevas mÃ©tricas sin afectar el resto
- âœ… **Testing:** Permite probar componentes de forma aislada

### 2. Procesamiento en Batch de 5
**DecisiÃ³n:** Enviar 5 transcripciones juntas por llamada API

**JustificaciÃ³n:**
- âœ… **Costo:** Procesar 1 transcripciÃ³n = 1 llamada. Con batch: 5 transcripciones = 1 llamada (5x mÃ¡s eficiente)
- âœ… **Tiempo:** Batch de 1 es muy lento (~10 min para 60 clientes). Batch de 5 reduce a ~3 min
- âœ… **Confiabilidad:** Batches muy grandes generan respuestas JSON incompletas o truncadas
- âœ… **Rate limits:** Optimiza el uso de los lÃ­mites de la API gratuita

### 3. SQLite como Base de Datos
**DecisiÃ³n:** SQLite local en lugar de PostgreSQL/MySQL

**JustificaciÃ³n:**
- âœ… **Zero-config:** No requiere servidor de BD
- âœ… **Portabilidad:** Un solo archivo `.db`
- âœ… **Suficiente:** Ã“ptimo para <10K registros

### 4. Stack Python: Pandas + Plotly + Streamlit
**DecisiÃ³n:** Ecosistema Python completo para anÃ¡lisis de datos

**JustificaciÃ³n:**
- âœ… **Python:** Lenguaje nativo para Data Science y ML
- âœ… **Pandas:** ManipulaciÃ³n de datos tabular (filtros, agregaciones, transformaciones)
- âœ… **Plotly:** GrÃ¡ficos interactivos
- âœ… **Velocidad de desarrollo:** Dashboard funcional en 3-5 dÃ­as
- âœ… **Python puro:** No requiere JavaScript
- âœ… **Reactivo nativo:** Filtros actualizan mÃ©tricas automÃ¡ticamente
- âœ… **Ideal para MVPs**

**Trade-off:** Limitado a ~1000 usuarios concurrentes (suficiente para este caso)

### 6. Sistema de Scoring de Leads
**DecisiÃ³n:** FÃ³rmula cuantitativa basada en 3 pilares + bonuses

**JustificaciÃ³n:**
```python
base_score = (volumen_score + urgencia_score + escalabilidad_score) / 3
final_score = base_score + trigger_bonus + budget_bonus

Donde:
- volumen_score: 0-100 segÃºn nivel de volumen semanal
  Â· Desconocido: 0 pts
  Â· Bajo (<100): 20 pts
  Â· Medio (100-250): 50 pts
  Â· Alto (251-500): 80 pts
  Â· Muy Alto (>500): 100 pts

- urgencia_score: 0-100 segÃºn nivel de urgencia
  Â· Baja: 30 pts
  Â· Media: 60 pts
  Â· Alta: 100 pts

- escalabilidad_score: 0-100 segÃºn potencial de crecimiento
  Â· Picos estacionales: 100 pts
  Â· Soporte multicanal: 100 pts
  Â· Escalamiento automÃ¡tico: 90 pts
  Â· 3+ add-ons: 70 pts
  Â· Base: 40 pts

- trigger_bonus: +0 a +5 pts
  Â· RecomendaciÃ³n/Evento/LinkedIn: +5 pts
  Â· BÃºsqueda activa (Google): +3 pts
  Â· Sin fuente clara: 0 pts

- budget_bonus: +0 a +5 pts
  Â· Indicadores internacionales: +5 pts
  Â· Sectores de alto presupuesto: +3 pts
  Â· Sin info: 0 pts
```

**Ventaja:** PriorizaciÃ³n objetiva y replicable de leads.

### 7. Retry con Exponential Backoff
**DecisiÃ³n:** Reintentar 3 veces con delays incrementales (1s, 2s, 4s)

**JustificaciÃ³n:**
- âœ… **Resilencia:** Maneja fallos temporales de API
- âœ… **Graceful degradation:** Usa valores por defecto si falla definitivamente
- âœ… **No bloquea:** El usuario ve progreso incluso con errores parciales

### 8. NormalizaciÃ³n de Volumen
**DecisiÃ³n:** Convertir todo a "interacciones por semana"

**JustificaciÃ³n:**
```
Problema: Clientes mencionan "80 diarias", "500 semanales", "2000 mensuales"
SoluciÃ³n: Normalizar en el prompt de Gemini
  - Diarias â†’ Ã— 7
  - Semanales â†’ sin cambio
  - Mensuales â†’ Ã· 4
```

**Ventaja:** Permite comparar clientes de forma consistente.
